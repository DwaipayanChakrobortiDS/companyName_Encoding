{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully converted to CSV.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the joblib file\n",
    "data = joblib.load(r'C:\\Users\\Dwaipayan C\\Downloads\\Monthly_Income_Estimation_Target_Encoded_Artifacts_companytrgencode.joblib')\n",
    "\n",
    "# Ensure that the loaded data is a DataFrame\n",
    "if isinstance(data, pd.DataFrame):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    data.to_csv('output_file_name.csv', index=False)\n",
    "    print(\"Data has been successfully converted to CSV.\")\n",
    "else:\n",
    "    print(\"Loaded data is not a DataFrame. Please ensure your joblib file contains a DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been successfully converted to CSV and compressed into a ZIP file.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Load the joblib file\n",
    "data = joblib.load(r'C:\\Users\\Dwaipayan C\\Downloads\\Monthly_Income_Estimation_Target_Encoded_Artifacts_companytrgencode.joblib')\n",
    "\n",
    "# Ensure that the loaded data is a DataFrame\n",
    "if isinstance(data, pd.DataFrame):\n",
    "    # Save the DataFrame to a CSV file\n",
    "    csv_file = 'output_file_name.csv'\n",
    "    data.to_csv(csv_file, index=False)\n",
    "    \n",
    "    # Compress the CSV file into a ZIP file\n",
    "    zip_file = 'output_file_name.zip'\n",
    "    with zipfile.ZipFile(zip_file, 'w', zipfile.ZIP_DEFLATED) as z:\n",
    "        z.write(csv_file)\n",
    "    \n",
    "    print(\"Data has been successfully converted to CSV and compressed into a ZIP file.\")\n",
    "else:\n",
    "    print(\"Loaded data is not a DataFrame. Please ensure your joblib file contains a DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    global_mean  smoothing_factor       loan_company_name  \\\n",
      "0  30892.506245                15                     NaN   \n",
      "1  30892.506245                15  Expert Security Agency   \n",
      "2  30892.506245                15  leekie enterprises inc   \n",
      "3  30892.506245                15          Mangiboa Store   \n",
      "4  30892.506245                15           Fruits Vendor   \n",
      "\n",
      "   freq_encodedcompanyName  category_mean_companyName  \\\n",
      "0                      NaN                        NaN   \n",
      "1                      1.0               25000.000000   \n",
      "2                      1.0               28000.000000   \n",
      "3                      1.0               15000.000000   \n",
      "4                      3.0               28333.333333   \n",
      "\n",
      "   category_size_companyName  target_encodedcompanyName  \\\n",
      "0                        NaN               30892.506245   \n",
      "1                        1.0               30524.224605   \n",
      "2                        1.0               30711.724605   \n",
      "3                        1.0               29899.224605   \n",
      "4                        3.0               30465.977426   \n",
      "\n",
      "   encoded_company_name_group  \n",
      "0                         NaN  \n",
      "1                30524.224605  \n",
      "2                30711.724605  \n",
      "3                29899.224605  \n",
      "4                91397.932279  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(r'C:\\Users\\Dwaipayan C\\OneDrive\\Learning\\Projects\\Income_Estimation\\output_file_name.csv')\n",
    "\n",
    "# Preview the data\n",
    "print(df.head())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64771"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['loan_company_name'].drop_duplicates().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_company_name              clean_name\n",
      "0                     NaN                     nan\n",
      "1  Expert Security Agency  expert security agency\n",
      "2  leekie enterprises inc      leekie enterprises\n",
      "3          Mangiboa Store          mangiboa store\n",
      "4           Fruits Vendor           fruits vendor\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to clean company names\n",
    "def preprocess_name(name):\n",
    "    name = str(name).lower()  # Convert to lowercase\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    # Remove common suffixes\n",
    "    suffixes = ['inc', 'incorporated', 'corp', 'corporation', 'ltd', 'limited', 'co', 'company', 'plc']\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(suffixes))\n",
    "    name = re.sub(pattern, '', name)\n",
    "    name = ' '.join(name.split())  # Remove extra spaces\n",
    "    return name\n",
    "\n",
    "# Apply preprocessing\n",
    "df['clean_name'] = df['loan_company_name'].apply(preprocess_name)\n",
    "\n",
    "# Preview cleaned names\n",
    "print(df[['loan_company_name', 'clean_name']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Company names have been standardized and saved to 'standardized_company_names.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Function to clean company names\n",
    "def preprocess_name(name):\n",
    "    name = str(name).lower()  # Convert to lowercase\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)  # Remove punctuation\n",
    "    # Remove common suffixes\n",
    "    suffixes = ['inc', 'incorporated', 'corp', 'corporation', 'ltd', 'limited', 'co', 'company', 'plc']\n",
    "    pattern = r'\\b(?:{})\\b'.format('|'.join(suffixes))\n",
    "    name = re.sub(pattern, '', name)\n",
    "    name = ' '.join(name.split())  # Remove extra spaces\n",
    "    return name\n",
    "\n",
    "# Load your data\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\Dwaipayan C\\OneDrive\\Learning\\Projects\\Income_Estimation\\output_file_name.csv')\n",
    "# Apply preprocessing\n",
    "df['clean_name'] = df['loan_company_name'].apply(preprocess_name)\n",
    "\n",
    "# Get a list of unique cleaned names\n",
    "unique_names = df['clean_name'].unique()\n",
    "\n",
    "# Create a dictionary to map similar names\n",
    "name_mapping = {}\n",
    "\n",
    "for name in unique_names:\n",
    "    if name in name_mapping.values():\n",
    "        continue  # Skip if already mapped\n",
    "    # Find matches with a similarity score above the threshold\n",
    "    matches = process.extract(\n",
    "        name,\n",
    "        unique_names,\n",
    "        scorer=fuzz.token_sort_ratio,  # Use fuzz.token_sort_ratio here\n",
    "        score_cutoff=90  # Adjust this threshold as needed\n",
    "    )\n",
    "    # Map similar names to the representative name\n",
    "    for match_name, score, _ in matches:\n",
    "        name_mapping[match_name] = name\n",
    "\n",
    "# Map the standardized names back to the DataFrame\n",
    "df['standardized_name'] = df['clean_name'].map(name_mapping)\n",
    "\n",
    "# Optionally, format the standardized names\n",
    "df['standardized_name'] = df['standardized_name'].str.title()\n",
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "df.to_csv('standardized_company_names.csv', index=False)\n",
    "\n",
    "print(\"Company names have been standardized and saved to 'standardized_company_names.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_company_name       standardized_name\n",
      "0                     NaN                   Noona\n",
      "1  Expert Security Agency  Expert Security Agency\n",
      "2  leekie enterprises inc  leekie enterprises inc\n",
      "3          Mangiboa Store          Mangiboa Store\n",
      "4           Fruits Vendor           Fruits Vendor\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jellyfish\n",
    "\n",
    "# Function to get phonetic code\n",
    "def get_phonetic_code(name):\n",
    "    name = str(name)\n",
    "    code = jellyfish.metaphone(name)\n",
    "    return code\n",
    "\n",
    "# Apply phonetic coding\n",
    "df['phonetic_code'] = df['loan_company_name'].apply(get_phonetic_code)\n",
    "\n",
    "# Map standardized names based on phonetic codes\n",
    "df['standardized_name'] = df.groupby('phonetic_code')['loan_company_name'].transform('first')\n",
    "\n",
    "# Preview the results\n",
    "print(df[['loan_company_name', 'standardized_name']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned data to a new csv file\n",
    "\n",
    "df.to_csv(\"Phonetic_cleaned_company_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Untilizing Hashing of n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_company_name       standardized_name\n",
      "0                     NaN          Mangiboa Store\n",
      "1  Expert Security Agency  Expert Security Agency\n",
      "2  leekie enterprises inc  leekie enterprises inc\n",
      "3          Mangiboa Store          Mangiboa Store\n",
      "4           Fruits Vendor          Mangiboa Store\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "# Function to generate n-gram hash\n",
    "def ngram_hash(name, n=3):\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    tokens = name.split()\n",
    "    ngrams = [''.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    combined = ' '.join(ngrams)\n",
    "    return hashlib.md5(combined.encode()).hexdigest()\n",
    "\n",
    "# Apply n-gram hashing\n",
    "df['ngram_hash'] = df['loan_company_name'].apply(ngram_hash)\n",
    "\n",
    "# Map standardized names\n",
    "df['standardized_name'] = df.groupby('ngram_hash')['loan_company_name'].transform('first')\n",
    "\n",
    "# Preview the results\n",
    "print(df[['loan_company_name', 'standardized_name']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Ngram_cleaned_company_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Exact Matching with Extensive Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_company_name       standardized_name\n",
      "0                     NaN                     nan\n",
      "1  Expert Security Agency  agency expert security\n",
      "2  leekie enterprises inc      enterprises leekie\n",
      "3          Mangiboa Store          mangiboa store\n",
      "4           Fruits Vendor           fruits vendor\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "\n",
    "# Function to perform aggressive normalization\n",
    "def aggressive_normalize(name):\n",
    "    name = str(name).lower()\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ascii', 'ignore').decode('utf-8')\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    name = re.sub(r'\\d+', '', name)  # Remove digits\n",
    "    stop_words = ['the', 'and', 'of', 'in', 'a']\n",
    "    tokens = [word for word in name.split() if word not in stop_words]\n",
    "    suffixes = ['inc', 'incorporated', 'corp', 'corporation', 'company', 'co', 'ltd', 'limited', 'plc']\n",
    "    tokens = [word for word in tokens if word not in suffixes]\n",
    "    name = ' '.join(sorted(tokens))\n",
    "    return name.strip()\n",
    "\n",
    "# Apply aggressive normalization\n",
    "df['standardized_name'] = df['loan_company_name'].apply(aggressive_normalize)\n",
    "\n",
    "# Preview the results\n",
    "print(df[['loan_company_name', 'standardized_name']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Aggressive_cleaned_company_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Clustering with String Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loan_company_name       standardized_name\n",
      "0                     NaN                    None\n",
      "1  Expert Security Agency  Expert Security Agency\n",
      "2  leekie enterprises inc  Expert Security Agency\n",
      "3          Mangiboa Store  Expert Security Agency\n",
      "4           Fruits Vendor  Expert Security Agency\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Preprocess names\n",
    "def preprocess(name):\n",
    "    name = str(name).lower()\n",
    "    name = re.sub(r'[^\\w\\s]', '', name)\n",
    "    return name\n",
    "\n",
    "df['clean_name'] = df['loan_company_name'].apply(preprocess)\n",
    "\n",
    "# Vectorize names\n",
    "vectorizer = TfidfVectorizer(min_df=1, analyzer='char', ngram_range=(2,3))\n",
    "tfidf_matrix = vectorizer.fit_transform(df['clean_name'])\n",
    "\n",
    "# Cluster names using DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2, metric='cosine')\n",
    "dbscan.fit(tfidf_matrix)\n",
    "\n",
    "# Assign cluster labels\n",
    "df['cluster'] = dbscan.labels_\n",
    "\n",
    "# Map standardized names\n",
    "df['standardized_name'] = df.groupby('cluster')['loan_company_name'].transform('first')\n",
    "\n",
    "# Preview the results\n",
    "print(df[['loan_company_name', 'standardized_name']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
